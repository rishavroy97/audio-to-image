{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81b47289d810c7ca",
   "metadata": {},
   "source": [
    "## Audio2Image\n",
    "\n",
    "Run this notebook to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ed6448655234ad0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T18:35:34.639159Z",
     "start_time": "2024-04-22T18:35:28.581356Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting PySoundFile\n",
      "  Downloading PySoundFile-0.9.0.post1-py2.py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: cffi>=0.6 in /ext3/miniconda3/lib/python3.12/site-packages (from PySoundFile) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /ext3/miniconda3/lib/python3.12/site-packages (from cffi>=0.6->PySoundFile) (2.21)\n",
      "Downloading PySoundFile-0.9.0.post1-py2.py3-none-any.whl (24 kB)\n",
      "Installing collected packages: PySoundFile\n",
      "Successfully installed PySoundFile-0.9.0.post1\n"
     ]
    }
   ],
   "source": [
    "!pip install PySoundFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcf0a619a1613ad7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T18:49:08.204887Z",
     "start_time": "2024-04-22T18:49:08.191500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torchaudio in /home/as18464/.local/lib/python3.12/site-packages (2.2.2)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.17.2-cp312-cp312-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: torch==2.2.2 in /ext3/miniconda3/lib/python3.12/site-packages (from torchaudio) (2.2.2)\n",
      "Requirement already satisfied: filelock in /ext3/miniconda3/lib/python3.12/site-packages (from torch==2.2.2->torchaudio) (3.13.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /ext3/miniconda3/lib/python3.12/site-packages (from torch==2.2.2->torchaudio) (4.11.0)\n",
      "Requirement already satisfied: sympy in /ext3/miniconda3/lib/python3.12/site-packages (from torch==2.2.2->torchaudio) (1.12)\n",
      "Requirement already satisfied: networkx in /ext3/miniconda3/lib/python3.12/site-packages (from torch==2.2.2->torchaudio) (3.3)\n",
      "Requirement already satisfied: jinja2 in /ext3/miniconda3/lib/python3.12/site-packages (from torch==2.2.2->torchaudio) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /ext3/miniconda3/lib/python3.12/site-packages (from torch==2.2.2->torchaudio) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /ext3/miniconda3/lib/python3.12/site-packages (from torch==2.2.2->torchaudio) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /ext3/miniconda3/lib/python3.12/site-packages (from torch==2.2.2->torchaudio) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /ext3/miniconda3/lib/python3.12/site-packages (from torch==2.2.2->torchaudio) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /ext3/miniconda3/lib/python3.12/site-packages (from torch==2.2.2->torchaudio) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /ext3/miniconda3/lib/python3.12/site-packages (from torch==2.2.2->torchaudio) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /ext3/miniconda3/lib/python3.12/site-packages (from torch==2.2.2->torchaudio) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /ext3/miniconda3/lib/python3.12/site-packages (from torch==2.2.2->torchaudio) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /ext3/miniconda3/lib/python3.12/site-packages (from torch==2.2.2->torchaudio) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /ext3/miniconda3/lib/python3.12/site-packages (from torch==2.2.2->torchaudio) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /ext3/miniconda3/lib/python3.12/site-packages (from torch==2.2.2->torchaudio) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /ext3/miniconda3/lib/python3.12/site-packages (from torch==2.2.2->torchaudio) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /ext3/miniconda3/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.2->torchaudio) (12.4.127)\n",
      "Requirement already satisfied: numpy in /home/as18464/.local/lib/python3.12/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /ext3/miniconda3/lib/python3.12/site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /ext3/miniconda3/lib/python3.12/site-packages (from jinja2->torch==2.2.2->torchaudio) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /ext3/miniconda3/lib/python3.12/site-packages (from sympy->torch==2.2.2->torchaudio) (1.3.0)\n",
      "Downloading torchvision-0.17.2-cp312-cp312-manylinux1_x86_64.whl (6.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torchvision\n",
      "Successfully installed torchvision-0.17.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ext3/miniconda3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "!pip install torchaudio torchvision\n",
    "import torch\n",
    "import torchaudio\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47775be7939979f3",
   "metadata": {},
   "source": [
    "### Step 1: Create Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30bda34acf377236",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T18:49:08.791788Z",
     "start_time": "2024-04-22T18:49:08.784674Z"
    }
   },
   "outputs": [],
   "source": [
    "IMG_TRANSFORM = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((256, 256)),\n",
    "    torchvision.transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d687d8b775994fc2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T18:49:09.115512Z",
     "start_time": "2024-04-22T18:49:09.107300Z"
    }
   },
   "outputs": [],
   "source": [
    "NEW_COLUMN_NAMES = {\n",
    "    '---g-f_I2yQ': 'youtube_video_id',\n",
    "    '1': 'start_seconds',\n",
    "    'people marching': 'label',\n",
    "    'test': 'split',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "375cfca40a74a166",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T19:03:15.228307Z",
     "start_time": "2024-04-22T19:03:15.204203Z"
    }
   },
   "outputs": [],
   "source": [
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, csv_file, audio_dir, img_dir, img_transform=None, embeddings=None):\n",
    "        self.audio_dir = audio_dir\n",
    "        self.img_dir = img_dir\n",
    "        self.img_transform = img_transform\n",
    "        self.embeddings = embeddings\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.rename_columns()\n",
    "        self.add_columns()\n",
    "        self.remove_invalid_rows()\n",
    "\n",
    "    @staticmethod\n",
    "    def check_validity(image_path):\n",
    "        try:\n",
    "            Image.open(image_path)\n",
    "            return True\n",
    "        except:\n",
    "            return False\n",
    "\n",
    "    def remove_invalid_rows(self):\n",
    "        self.df['is_valid'] = self.df['img_path'].apply(AudioDataset.check_validity)\n",
    "        self.df = self.df[self.df['is_valid'] == True]\n",
    "        self.df = self.df.drop(columns=['is_valid'])\n",
    "\n",
    "    def rename_columns(self):\n",
    "        self.df.rename(columns=NEW_COLUMN_NAMES, inplace=True)\n",
    "\n",
    "    def add_columns(self):\n",
    "        self.df['audio_path'] = self.df['youtube_video_id'].apply(\n",
    "            lambda x: self.audio_dir + '/' + 'audio_' + x + '.wav')\n",
    "        self.df['img_path'] = self.df['youtube_video_id'].apply(lambda x: self.img_dir + '/' + 'image_' + x + '.jpg')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        print(f\"Index is {idx}\")\n",
    "        if idx >= len(self.df):\n",
    "            return None, None\n",
    "        \n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        else:\n",
    "            idx = [idx]\n",
    "        audio_path = self.df.loc[idx, 'audio_path'].values[0]\n",
    "        waveform, sample_rate = torchaudio.load(audio_path, normalize=True)\n",
    "        transform = torchaudio.transforms.Resample(sample_rate, sample_rate / 10)\n",
    "        waveform = transform(waveform)\n",
    "\n",
    "        img_path = self.df.loc[idx, 'img_path'].values[0]\n",
    "        img = Image.open(img_path)\n",
    "\n",
    "        if self.img_transform is not None:\n",
    "            img = self.img_transform(img)\n",
    "\n",
    "        if self.embeddings is not None:\n",
    "            waveform = self.embeddings(waveform)\n",
    "\n",
    "        return waveform, img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "572ad207ccd47bfd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T19:03:15.592470Z",
     "start_time": "2024-04-22T19:03:15.585764Z"
    }
   },
   "outputs": [],
   "source": [
    "CSV_FILE = './vggsound.csv'\n",
    "AUDIO_DIR = './data/audio'\n",
    "IMG_DIR = './data/image'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d92a70d884be8ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T19:03:23.467663Z",
     "start_time": "2024-04-22T19:03:15.945812Z"
    }
   },
   "outputs": [],
   "source": [
    "audio2image_dataset = AudioDataset(CSV_FILE, AUDIO_DIR, IMG_DIR, IMG_TRANSFORM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6939bf8f0085bdb0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T19:03:23.476265Z",
     "start_time": "2024-04-22T19:03:23.470685Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e49cb975cb0fc8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T19:03:23.487244Z",
     "start_time": "2024-04-22T19:03:23.478278Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m audio2image_dataloader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(audio2image_dataset, batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:350\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# map-style\u001b[39;00m\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shuffle:\n\u001b[0;32m--> 350\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m RandomSampler(dataset, generator\u001b[38;5;241m=\u001b[39mgenerator)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    351\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    352\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m SequentialSampler(dataset)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.12/site-packages/torch/utils/data/sampler.py:143\u001b[0m, in \u001b[0;36mRandomSampler.__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplacement should be a boolean value, but got replacement=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplacement\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_samples should be a positive integer value, but got num_samples=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "audio2image_dataloader = torch.utils.data.DataLoader(audio2image_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8f993c1df0fc9689",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T19:05:56.854837Z",
     "start_time": "2024-04-22T19:05:56.544042Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index is 0\n",
      "tensor([[[-0.0183, -0.0491, -0.0259,  ...,  0.0666,  0.0817,  0.0243],\n",
      "         [-0.0183, -0.0491, -0.0259,  ...,  0.0666,  0.0817,  0.0243]]])\n",
      "tensor([[[[0.2353, 0.2314, 0.2353,  ..., 0.3020, 0.3176, 0.3176],\n",
      "          [0.2510, 0.2471, 0.2431,  ..., 0.3059, 0.3216, 0.3216],\n",
      "          [0.2627, 0.2588, 0.2588,  ..., 0.3176, 0.3294, 0.3294],\n",
      "          ...,\n",
      "          [0.1608, 0.1608, 0.1608,  ..., 0.0745, 0.0784, 0.0863],\n",
      "          [0.1608, 0.1608, 0.1608,  ..., 0.0706, 0.0745, 0.0863],\n",
      "          [0.1647, 0.1647, 0.1647,  ..., 0.0706, 0.0745, 0.0824]],\n",
      "\n",
      "         [[0.2314, 0.2275, 0.2314,  ..., 0.2510, 0.2667, 0.2667],\n",
      "          [0.2510, 0.2471, 0.2431,  ..., 0.2588, 0.2745, 0.2745],\n",
      "          [0.2627, 0.2588, 0.2588,  ..., 0.2745, 0.2863, 0.2863],\n",
      "          ...,\n",
      "          [0.1804, 0.1804, 0.1804,  ..., 0.0706, 0.0745, 0.0824],\n",
      "          [0.1804, 0.1804, 0.1804,  ..., 0.0667, 0.0706, 0.0824],\n",
      "          [0.1843, 0.1843, 0.1843,  ..., 0.0667, 0.0706, 0.0784]],\n",
      "\n",
      "         [[0.2118, 0.2078, 0.2118,  ..., 0.2275, 0.2431, 0.2431],\n",
      "          [0.2235, 0.2196, 0.2157,  ..., 0.2353, 0.2510, 0.2510],\n",
      "          [0.2314, 0.2275, 0.2275,  ..., 0.2510, 0.2627, 0.2627],\n",
      "          ...,\n",
      "          [0.1961, 0.1961, 0.1961,  ..., 0.0627, 0.0667, 0.0745],\n",
      "          [0.1961, 0.1961, 0.1961,  ..., 0.0588, 0.0627, 0.0745],\n",
      "          [0.2000, 0.2000, 0.2000,  ..., 0.0588, 0.0627, 0.0706]]]])\n",
      "Index is 2\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index([2], dtype='int32')] are in the [index]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[129], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m wave, image \u001b[38;5;129;01min\u001b[39;00m audio2image_dataloader:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(wave)\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(image)\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[119], line 45\u001b[0m, in \u001b[0;36mAudioDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     44\u001b[0m     idx \u001b[38;5;241m=\u001b[39m [idx]\n\u001b[1;32m---> 45\u001b[0m audio_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39mloc[idx, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_path\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     46\u001b[0m waveform, sample_rate \u001b[38;5;241m=\u001b[39m torchaudio\u001b[38;5;241m.\u001b[39mload(audio_path, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     47\u001b[0m transform \u001b[38;5;241m=\u001b[39m torchaudio\u001b[38;5;241m.\u001b[39mtransforms\u001b[38;5;241m.\u001b[39mResample(sample_rate, sample_rate \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1184\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_value(\u001b[38;5;241m*\u001b[39mkey, takeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_takeable)\n\u001b[1;32m-> 1184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_tuple(key)\n\u001b[0;32m   1185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1186\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1368\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1366\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m suppress(IndexingError):\n\u001b[0;32m   1367\u001b[0m     tup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_ellipsis(tup)\n\u001b[1;32m-> 1368\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_lowerdim(tup)\n\u001b[0;32m   1370\u001b[0m \u001b[38;5;66;03m# no multi-index, so validate all of the indexers\u001b[39;00m\n\u001b[0;32m   1371\u001b[0m tup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_tuple_indexer(tup)\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1089\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_lowerdim\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1087\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m section\n\u001b[0;32m   1088\u001b[0m         \u001b[38;5;66;03m# This is an elided recursive call to iloc/loc\u001b[39;00m\n\u001b[1;32m-> 1089\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(section, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)[new_key]\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m IndexingError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot applicable\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1191\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1189\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m   1190\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[1;32m-> 1191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_axis(maybe_callable, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1420\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1417\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1418\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index with multidimensional key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_iterable(key, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m   1422\u001b[0m \u001b[38;5;66;03m# nested tuple slicing\u001b[39;00m\n\u001b[0;32m   1423\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1360\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1357\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[0;32m   1359\u001b[0m \u001b[38;5;66;03m# A collection of keys\u001b[39;00m\n\u001b[1;32m-> 1360\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_listlike_indexer(key, axis)\n\u001b[0;32m   1361\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[0;32m   1362\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1363\u001b[0m )\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1558\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1555\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[0;32m   1556\u001b[0m axis_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis_name(axis)\n\u001b[1;32m-> 1558\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, axis_name)\n\u001b[0;32m   1560\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[0;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[1;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index([2], dtype='int32')] are in the [index]\""
     ]
    }
   ],
   "source": [
    "for wave, image in audio2image_dataloader:\n",
    "    print(wave)\n",
    "    print(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd97dc5224dac80c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
